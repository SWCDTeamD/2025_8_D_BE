from __future__ import annotations
from typing import Any, Dict, List, Optional
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession
from backend.repositories.database import AsyncSessionLocal
from backend.repositories.morphology_utils import normalize_query_morphology
import os

# SentenceTransformers (ë¡œì»¬ ëª¨ë¸)
try:
    from sentence_transformers import SentenceTransformer  # type: ignore
    _HAS_EMBEDDING = True
except ImportError:
    SentenceTransformer = None  # type: ignore
    _HAS_EMBEDDING = False

# OpenAI ì„ë² ë”© (ì„ íƒì )
try:
    from openai import OpenAI  # type: ignore
    _HAS_OPENAI = True
except ImportError:
    OpenAI = None  # type: ignore
    _HAS_OPENAI = False

_EMBEDDING_MODEL: Optional[Any] = None
_OPENAI_CLIENT: Optional[Any] = None

def get_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ë°˜í™˜
    
    í™˜ê²½ ë³€ìˆ˜ EMBEDDING_MODELë¡œ ì„ íƒ:
    - "openai" â†’ OpenAI text-embedding-3-small (1536ì°¨ì›)
    - "kosimcse" or None â†’ KoSimCSE (768ì°¨ì›, ê¸°ë³¸ê°’)
    
    ì£¼ì˜: DBì— ì €ì¥ëœ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ ë²¡í„° ê²€ìƒ‰ì´ ì •ìƒ ì‘ë™í•¨!
    """
    global _EMBEDDING_MODEL, _OPENAI_CLIENT
    
    embedding_model_type = os.getenv("EMBEDDING_MODEL", "kosimcse").lower()
    
    if embedding_model_type == "openai":
        # OpenAI ì„ë² ë”© ì‚¬ìš©
        if not _HAS_OPENAI or OpenAI is None:
            print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")
            return None
        
        if _OPENAI_CLIENT is None:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                print("âš ï¸ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            _OPENAI_CLIENT = OpenAI(api_key=api_key)
            print("âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (text-embedding-3-small, 1536ì°¨ì›)")
        
        return _OPENAI_CLIENT
    else:
        # KoSimCSE ì„ë² ë”© ì‚¬ìš© (ê¸°ë³¸ê°’)
        if not _HAS_EMBEDDING or SentenceTransformer is None:
            return None
        if _EMBEDDING_MODEL is None:
            # ETL íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© (BM-K/KoSimCSE-roberta-multitask)
            _EMBEDDING_MODEL = SentenceTransformer('BM-K/KoSimCSE-roberta-multitask')
            print("âœ… KoSimCSE ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (BM-K/KoSimCSE-roberta-multitask, 768ì°¨ì›)")
        return _EMBEDDING_MODEL

class DocumentRepository:
    def __init__(self, session: Optional[AsyncSession] = None) -> None:
        self.session = session

    async def _get_session(self) -> AsyncSession:
        """ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€, í•˜ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ê¶Œì¥)"""
        if self.session:
            return self.session
        return AsyncSessionLocal()

    async def semantic_search(
        self, 
        query: str, 
        limit: int, 
        exclude_negative: bool = True,
        exclude_patterns: Optional[List[str]] = None,
        segment_filter: Optional[List[str]] = None,
        min_similarity: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            exclude_negative: Trueë©´ ë¶€ì • í‘œí˜„ì´ í¬í•¨ëœ ì„¸ê·¸ë¨¼íŠ¸ ì œì™¸ (ì˜ˆ: "í‚¤ì›Œë³¸ ì ì´ ì—†ë‹¤")
            segment_filter: ê²€ìƒ‰í•  ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰)
        """
        # [ìˆ˜ì • 1] ì„¸ì…˜ ê´€ë¦¬ ë¡œì§ ì¶”ê°€
        # self.sessionì´ ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ê³  'ë°˜ë“œì‹œ ë‹«ëŠ”ë‹¤'
        session = self.session if self.session else AsyncSessionLocal()
        should_close = self.session is None
        
        embedding_model = get_embedding_model()
        if not embedding_model:
            if should_close:
                await session.close()
            print("  âš ï¸ ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ ë²¡í„° ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []
        
        try:
            # ì„ë² ë”© ìƒì„± (ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¦„)
            embedding_model_type = os.getenv("EMBEDDING_MODEL", "kosimcse").lower()
            
            if embedding_model_type == "openai":
                # OpenAI ì„ë² ë”© API í˜¸ì¶œ
                response = embedding_model.embeddings.create(
                    model="text-embedding-3-small",  # 1536ì°¨ì›
                    input=query
                )
                query_embedding = response.data[0].embedding
            else:
                # KoSimCSE (ë¡œì»¬ ëª¨ë¸)
                query_embedding = embedding_model.encode(query, convert_to_numpy=True).tolist()
            
            embedding_str = "[" + ",".join(map(str, query_embedding)) + "]"
            
            # ë¶€ì • í‘œí˜„ í•„í„°ë§ ì¡°ê±´ ì¶”ê°€ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
            negative_filter = ""
            negative_filter_params = {}  # SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            if exclude_negative:
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì œê³µëœ exclude_patterns ìš°ì„  ì‚¬ìš©
                if exclude_patterns:
                    # SQL ì¸ì ì…˜ ë°©ì§€: íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ì‚¬ìš©
                    pattern_conditions = " OR ".join([
                        f"summary_text LIKE :neg_pattern_{i}"
                        for i in range(len(exclude_patterns))
                    ])
                    negative_filter = f"""
                      AND NOT ({pattern_conditions})
                    """
                    # íŒ¨í„´ì„ íŒŒë¼ë¯¸í„°ë¡œ ì¶”ê°€ (% í¬í•¨í•˜ì—¬ ì „ë‹¬)
                    for i, pattern in enumerate(exclude_patterns):
                        negative_filter_params[f"neg_pattern_{i}"] = f"%{pattern}%"
                else:
                    # ê¸°ë³¸ íŒ¨í„´ (í•˜ìœ„ í˜¸í™˜ì„±)
                    positive_keywords = ["í‚¤ìš°ëŠ”", "í‚¤ìš´", "í‚¤ì›Œ", "ë³´ìœ ", "ìˆ", "í•œë‹¤", "ì¤‘ì´ë‹¤"]
                    negative_keywords = ["ì—†ë‹¤", "ì—†ìŒ", "ì•ˆ", "ëª»", "í•˜ì§€ ì•Š", "í•˜ì§€ ì•ŠëŠ”ë‹¤"]
                    
                    # ì¿¼ë¦¬ì— ê¸ì • í‚¤ì›Œë“œê°€ ìˆê³  ë¶€ì • í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¶€ì • í‘œí˜„ ì œì™¸
                    has_positive = any(kw in query for kw in positive_keywords)
                    has_negative = any(kw in query for kw in negative_keywords)
                    
                    if has_positive and not has_negative:
                        # ë¶€ì • í‘œí˜„ì´ í¬í•¨ëœ ì„¸ê·¸ë¨¼íŠ¸ ì œì™¸ (ê°•í™”)
                        negative_filter = """
                          AND NOT (
                            summary_text LIKE '%ì—†ë‹¤%' 
                            OR summary_text LIKE '%ì—†ìŒ%'
                            OR summary_text LIKE '%í‚¤ì›Œë³¸ ì ì´ ì—†ë‹¤%'
                            OR summary_text LIKE '%í‚¤ìš´ ì ì´ ì—†ë‹¤%'
                            OR summary_text LIKE '%í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%í•˜ì§€ ì•ŠìŒ%'
                            OR summary_text LIKE '%ë°›ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì„ í˜¸í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì•ˆ í•œë‹¤%'
                            OR summary_text LIKE '%ì•ˆí•œë‹¤%'
                          )
                        """
            
            # ì„¸ê·¸ë¨¼íŠ¸ í•„í„° ì¡°ê±´
            segment_filter_clause = ""
            if segment_filter and len(segment_filter) > 0:
                segment_filter_clause = "AND segment_name = ANY(:segment_filter_array)"
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
            if min_similarity is None:
                try:
                    min_similarity = float(os.getenv("EMBEDDING_MIN_SIM", "0.60"))
                except Exception:
                    min_similarity = 0.60
            
            # ì¿¼ë¦¬ ìµœì í™”: segment_filterê°€ ìˆìœ¼ë©´ ë¨¼ì € í•„í„°ë§ (ì¸ë±ìŠ¤ í™œìš©)
            # WHERE ì ˆ ìˆœì„œ ìµœì í™”: segment_name í•„í„°ë¥¼ ë¨¼ì € ì ìš©í•˜ë©´ ë²¡í„° ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
            if segment_filter and len(segment_filter) > 0:
                # segment_nameì„ ë¨¼ì € í•„í„°ë§í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
                sql_query = text(f"""
                    SELECT 
                        panel_id,
                        segment_name,
                        summary_text,
                        1 - (embedding <=> CAST(:embedding_str AS vector)) as similarity
                    FROM panel_summary_segments
                    WHERE segment_name = ANY(:segment_filter_array)
                      AND embedding IS NOT NULL
                      {negative_filter}
                      AND (1 - (embedding <=> CAST(:embedding_str AS vector))) >= :min_sim
                    ORDER BY embedding <=> CAST(:embedding_str AS vector)
                    LIMIT :limit_val
                """)
            else:
                # segment_filterê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                sql_query = text(f"""
                    SELECT 
                        panel_id,
                        segment_name,
                        summary_text,
                        1 - (embedding <=> CAST(:embedding_str AS vector)) as similarity
                    FROM panel_summary_segments
                    WHERE embedding IS NOT NULL
                      {negative_filter}
                      AND (1 - (embedding <=> CAST(:embedding_str AS vector))) >= :min_sim
                    ORDER BY embedding <=> CAST(:embedding_str AS vector)
                    LIMIT :limit_val
                """)
            
            # limit ìµœì í™”: ë¶ˆí•„ìš”í•˜ê²Œ ë§ì´ ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ
            # ë²¡í„° ê²€ìƒ‰ì€ ì •í™•ë„ê°€ ë†’ìœ¼ë¯€ë¡œ limit * 2 ì •ë„ë©´ ì¶©ë¶„
            # RRF í†µí•©ì„ ìœ„í•´ ì•½ê°„ ì—¬ìœ ë¥¼ ë‘ë˜, ê³¼ë„í•˜ê²Œ ë§ì´ ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ
            effective_limit = min(limit * 2, 10000)  # ìµœëŒ€ 10,000ê°œë¡œ ì œí•œ
            
            params = {
                "embedding_str": embedding_str,
                "limit_val": effective_limit,
                "min_sim": min_similarity
            }
            if segment_filter and len(segment_filter) > 0:
                params["segment_filter_array"] = segment_filter
            # SQL ì¸ì ì…˜ ë°©ì§€: ë¶€ì • íŒ¨í„´ íŒŒë¼ë¯¸í„° ì¶”ê°€
            params.update(negative_filter_params)
            
            try:
                result = await session.execute(sql_query, params)
                rows = result.fetchall()
            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ íŠ¸ëœì­ì…˜ ë¡¤ë°±
                await session.rollback()
                print(f"  âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                raise
            
            if not rows:
                print(f"  âš ï¸ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (DBì— embedding ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ í•„ìš”)")
            
            # íŒ¨ë„ë³„ ì ìˆ˜ ì²˜ë¦¬: ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë§¤ì¹­ë˜ë©´ ì ìˆ˜ ì¤‘ì²© (í•©ì‚°)
            # ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” ê²ƒì€ ë” ê´€ë ¨ì„±ì´ ë†’ë‹¤ëŠ” ì‹ í˜¸
            panel_scores: Dict[str, List[float]] = {}  # íŒ¨ë„ë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
            panel_segments: Dict[str, Dict[str, float]] = {}  # íŒ¨ë„ë³„ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì ìˆ˜ (ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒìš©)
            
            for panel_id, segment_name, summary_text, similarity in rows:
                if panel_id:
                    panel_id_str = str(panel_id)
                    similarity_float = float(similarity) if similarity else 0.0
                    if panel_id_str not in panel_scores:
                        panel_scores[panel_id_str] = []
                    panel_scores[panel_id_str].append(similarity_float)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœê³  ì ìˆ˜ ì¶”ì 
                    if panel_id_str not in panel_segments:
                        panel_segments[panel_id_str] = {}
                    seg_name = segment_name or ""
                    if seg_name not in panel_segments[panel_id_str] or similarity_float > panel_segments[panel_id_str][seg_name]:
                        panel_segments[panel_id_str][seg_name] = similarity_float
            
            # íŒ¨ë„ë³„ ìµœì¢… ì ìˆ˜ ê³„ì‚°: í‰ê·  + ìµœê³ ê°’ ê°€ì¤‘í•© (ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ë³´ë„ˆìŠ¤)
            best_by_panel: Dict[str, float] = {}
            best_segment_by_panel: Dict[str, Optional[str]] = {}  # íŒ¨ë„ë³„ ëŒ€í‘œ ì„¸ê·¸ë¨¼íŠ¸
            
            for panel_id_str, scores in panel_scores.items():
                if scores:
                    avg_score = sum(scores) / len(scores)
                    max_score = max(scores)
                    # í‰ê·  70% + ìµœê³ ê°’ 30% (ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ì‹œ ë³´ë„ˆìŠ¤)
                    # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë§ì„ìˆ˜ë¡ í‰ê· ì´ ë†’ì•„ì ¸ì„œ ì ìˆ˜ ìƒìŠ¹
                    final_score = avg_score * 0.7 + max_score * 0.3
                    # ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 1.2ë°°)
                    segment_bonus = min(1.0 + (len(scores) - 1) * 0.1, 1.2)
                    best_by_panel[panel_id_str] = final_score * segment_bonus
                    
                    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
                    if panel_id_str in panel_segments:
                        best_seg = max(panel_segments[panel_id_str].items(), key=lambda x: x[1])[0]
                        best_segment_by_panel[panel_id_str] = best_seg if best_seg else None
            
            sorted_items = sorted(best_by_panel.items(), key=lambda x: x[1], reverse=True)[:limit]
            return [
                {
                    "panel_id": pid, 
                    "score": score, 
                    "source": "vector",
                    "segment_name": best_segment_by_panel.get(pid)  # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ê°€
                }
                for pid, score in sorted_items
            ]
        except Exception as e:
            print(f"  âŒ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
        finally:
            # [ì¤‘ìš”] ì—¬ê¸°ì„œ ì„¸ì…˜ì„ ë‹«ì•„ì¤ë‹ˆë‹¤!
            if should_close:
                await session.close()

    async def fulltext_search(
        self, 
        query: str, 
        limit: int, 
        use_or: bool = False,  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ì‹¤ì œë¡œëŠ” ë¬´ì‹œë¨)
        exclude_negative: bool = True,
        exclude_patterns: Optional[List[str]] = None,
        segment_filter: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """Full-Text Search (FTS) ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            use_or: (deprecated) í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ì§€ë§Œ í•­ìƒ AND ì—°ì‚° ì‚¬ìš©
            exclude_negative: ë¶€ì • í‘œí˜„ ì œì™¸ ì—¬ë¶€
            exclude_patterns: ì œì™¸í•  íŒ¨í„´ ëª©ë¡ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
            segment_filter: ê²€ìƒ‰í•  ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Note:
            - AND ì—°ì‚°ë§Œ ì‚¬ìš© (ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨ í•„ìš”)
            - ë¶€ì •ì–´ëŠ” FTS ì¿¼ë¦¬ì— ì§ì ‘ í¬í•¨ (LIKE ì‚¬í›„ í•„í„°ë§ ëŒ€ì‹ )
            - í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ ('korean' dictionary ì‚¬ìš©)
        """
        # [ìˆ˜ì • 1] ì„¸ì…˜ ê´€ë¦¬ ë¡œì§ ì¶”ê°€
        session = self.session if self.session else AsyncSessionLocal()
        should_close = self.session is None
        
        from sqlalchemy import bindparam
        try:
            # ë¶€ì • í‘œí˜„ í•„í„°ë§ ì¡°ê±´ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
            negative_filter = ""
            negative_filter_params = {}  # SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            if exclude_negative:
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì œê³µëœ exclude_patterns ìš°ì„  ì‚¬ìš©
                if exclude_patterns:
                    # SQL ì¸ì ì…˜ ë°©ì§€: íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ì‚¬ìš©
                    pattern_conditions = " OR ".join([
                        f"summary_text LIKE :neg_pattern_{i}"
                        for i in range(len(exclude_patterns))
                    ])
                    negative_filter = f"""
                      AND NOT ({pattern_conditions})
                    """
                    # íŒ¨í„´ì„ íŒŒë¼ë¯¸í„°ë¡œ ì¶”ê°€ (% í¬í•¨í•˜ì—¬ ì „ë‹¬)
                    for i, pattern in enumerate(exclude_patterns):
                        negative_filter_params[f"neg_pattern_{i}"] = f"%{pattern}%"
                else:
                    # ê¸°ë³¸ íŒ¨í„´ (í•˜ìœ„ í˜¸í™˜ì„±)
                    positive_keywords = ["í‚¤ìš°ëŠ”", "í‚¤ìš´", "í‚¤ì›Œ", "ë³´ìœ ", "ìˆ", "í•œë‹¤", "ì¤‘ì´ë‹¤"]
                    negative_keywords = ["ì—†ë‹¤", "ì—†ìŒ", "ì•ˆ", "ëª»", "í•˜ì§€ ì•Š", "í•˜ì§€ ì•ŠëŠ”ë‹¤"]
                    
                    has_positive = any(kw in query for kw in positive_keywords)
                    has_negative = any(kw in query for kw in negative_keywords)
                    
                    if has_positive and not has_negative:
                        # ë¶€ì • í‘œí˜„ë§Œ ì œì™¸ (í˜„ì¬ ìƒíƒœì™€ ê³¼ê±° ê²½í—˜ ëª¨ë‘ í¬í•¨)
                        # "í‚¤ìš´ ì ì´ ìˆë‹¤"ëŠ” ê³¼ê±° ê²½í—˜ì´ì§€ë§Œ í˜„ì¬ë„ í‚¤ìš¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í¬í•¨
                        # ë‹¨, ëª…í™•í•œ ë¶€ì • í‘œí˜„ë§Œ ì œì™¸
                        negative_filter = """
                          AND NOT (
                            summary_text LIKE '%ì—†ë‹¤%' 
                            OR summary_text LIKE '%ì—†ìŒ%'
                            OR summary_text LIKE '%í‚¤ì›Œë³¸ ì ì´ ì—†ë‹¤%'
                            OR summary_text LIKE '%í‚¤ìš´ ì ì´ ì—†ë‹¤%'
                            OR summary_text LIKE '%í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%í•˜ì§€ ì•ŠìŒ%'
                            OR summary_text LIKE '%ë°›ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì„ í˜¸í•˜ì§€ ì•ŠëŠ”ë‹¤%'
                            OR summary_text LIKE '%ì•ˆ í•œë‹¤%'
                            OR summary_text LIKE '%ì•ˆí•œë‹¤%'
                          )
                        """
            
            # FTS ì¿¼ë¦¬ ìƒì„± (í˜•íƒœì†Œ ë¶„ì„ ì ìš©)
            # ê²€ìƒ‰ì–´ë„ í˜•íƒœì†Œ ë¶„ì„ì„ ê±°ì³ ì¸ë±ì‹±ëœ í† í°ê³¼ ë§¤ì¹­ë˜ë„ë¡ í•¨
            print(f"      ğŸ”¤ FTS í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘: ì¿¼ë¦¬='{query}'")
            
            # í˜•íƒœì†Œ ë¶„ì„ì„ í†µí•œ í‚¤ì›Œë“œ ì •ê·œí™”
            normalized_query = normalize_query_morphology(query)
            
            if not normalized_query:
                # í˜•íƒœì†Œ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
                import re
                keywords = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query)
                keywords = [k for k in keywords if len(k) >= 2]
                if not keywords:
                    keywords = [k.strip() for k in query.split() if k.strip() and len(k.strip()) >= 2]
                
                if not keywords:
                    print(f"      âš ï¸ FTS ê²€ìƒ‰: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ (ì¿¼ë¦¬: {query})")
                    return []
                
                print(f"      âš ï¸ í˜•íƒœì†Œ ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {keywords}")
            else:
                # í˜•íƒœì†Œ ë¶„ì„ ì„±ê³µ: ì •ê·œí™”ëœ í‚¤ì›Œë“œ ì‚¬ìš©
                keywords = normalized_query.split()
                print(f"      âœ… í˜•íƒœì†Œ ë¶„ì„ ì™„ë£Œ: {keywords}")
            
            # [ìˆ˜ì •] plainto_tsqueryë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í‚¤ì›Œë“œë¥¼ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì „ë‹¬
            # plainto_tsqueryëŠ” ìë™ìœ¼ë¡œ AND ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ ' & ' ì—°ê²° ë¶ˆí•„ìš”
            final_query = ' '.join(keywords)
            print(f"      ğŸ“ FTS ì¿¼ë¦¬ (plainto_tsqueryìš©): {final_query}")
            
            # ì£¼ì˜: plainto_tsqueryëŠ” ë¶€ì •ì–´(!) ì—°ì‚°ìë¥¼ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
            # ë¶€ì •ì–´ í•„í„°ë§ì€ negative_filter (LIKE ì ˆ)ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            
            # SQL ì¿¼ë¦¬ ì‹¤í–‰ (ë¶€ì •ì–´ëŠ” ì¿¼ë¦¬ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ negative_filter ì œê±°)
            # [ìˆ˜ì •] to_tsquery ëŒ€ì‹  plainto_tsquery ì‚¬ìš© (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œë¥¼ AND ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬)
            # plainto_tsqueryëŠ” ì‚¬ìš©ì ì…ë ¥ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê³  íƒ€ì„ì•„ì›ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
            if segment_filter and len(segment_filter) > 0:
                # segment_nameì„ ë¨¼ì € í•„í„°ë§í•˜ì—¬ FTS ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
                sql_query = text(f"""
                    SELECT 
                        panel_id,
                        ts_rank(ts_vector_korean, plainto_tsquery('korean', :query_str)) as rank
                    FROM panel_summary_segments
                    WHERE segment_name = ANY(:segment_filter_array)
                      AND ts_vector_korean IS NOT NULL
                      AND ts_vector_korean @@ plainto_tsquery('korean', :query_str)
                      {negative_filter}
                    ORDER BY rank DESC
                    LIMIT :limit_val
                """)
            else:
                # segment_filterê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                sql_query = text(f"""
                    SELECT 
                        panel_id,
                        ts_rank(ts_vector_korean, plainto_tsquery('korean', :query_str)) as rank
                    FROM panel_summary_segments
                    WHERE ts_vector_korean IS NOT NULL
                      AND ts_vector_korean @@ plainto_tsquery('korean', :query_str)
                      {negative_filter}
                    ORDER BY rank DESC
                    LIMIT :limit_val
                """)
            
            # limit ìµœì í™”: ë¶ˆí•„ìš”í•˜ê²Œ ë§ì´ ê°€ì ¸ì˜¤ì§€ ì•ŠìŒ
            # FTS ê²€ìƒ‰ë„ limit * 2 ì •ë„ë©´ ì¶©ë¶„
            effective_limit = min(limit * 2, 10000)  # ìµœëŒ€ 10,000ê°œë¡œ ì œí•œ
            
            params = {
                "query_str": final_query,
                "limit_val": effective_limit
            }
            if segment_filter and len(segment_filter) > 0:
                params["segment_filter_array"] = segment_filter
            # SQL ì¸ì ì…˜ ë°©ì§€: ë¶€ì • íŒ¨í„´ íŒŒë¼ë¯¸í„° ì¶”ê°€
            params.update(negative_filter_params)
            
            try:
                result = await session.execute(sql_query, params)
                rows = result.fetchall()
            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ íŠ¸ëœì­ì…˜ ë¡¤ë°±
                await session.rollback()
                print(f"    âŒ FTS ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                raise
            
            if not rows:
                print(f"    âš ï¸ FTS ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¿¼ë¦¬: {query[:50]}, DBì— ts_vector_korean ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ í•„ìš”)")
            
            # íŒ¨ë„ë³„ ì ìˆ˜ ì²˜ë¦¬: ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë§¤ì¹­ë˜ë©´ ì ìˆ˜ ì¤‘ì²© (í•©ì‚°)
            # ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” ê²ƒì€ ë” ê´€ë ¨ì„±ì´ ë†’ë‹¤ëŠ” ì‹ í˜¸
            panel_scores: Dict[str, List[float]] = {}  # íŒ¨ë„ë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
            for panel_id, rank in rows:
                if panel_id:
                    panel_id_str = str(panel_id)
                    rank_float = float(rank) if rank else 0.0
                    if panel_id_str not in panel_scores:
                        panel_scores[panel_id_str] = []
                    panel_scores[panel_id_str].append(rank_float)
            
            # íŒ¨ë„ë³„ ìµœì¢… ì ìˆ˜ ê³„ì‚°: í‰ê·  + ìµœê³ ê°’ ê°€ì¤‘í•© (ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ë³´ë„ˆìŠ¤)
            best_by_panel: Dict[str, float] = {}
            for panel_id_str, scores in panel_scores.items():
                if scores:
                    avg_score = sum(scores) / len(scores)
                    max_score = max(scores)
                    # í‰ê·  70% + ìµœê³ ê°’ 30% (ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ì‹œ ë³´ë„ˆìŠ¤)
                    final_score = avg_score * 0.7 + max_score * 0.3
                    # ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 1.2ë°°)
                    segment_bonus = min(1.0 + (len(scores) - 1) * 0.1, 1.2)
                    best_by_panel[panel_id_str] = final_score * segment_bonus
            sorted_items = sorted(best_by_panel.items(), key=lambda x: x[1], reverse=True)[:limit]
            return [
                {"panel_id": pid, "score": score, "source": "fts"}
                for pid, score in sorted_items
            ]
        except Exception as e:
            print(f"    âŒ FTS ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
        finally:
            # [ì¤‘ìš”] ì„¸ì…˜ ë‹«ê¸°
            if should_close:
                await session.close()

    async def semantic_search_with_filters(
        self, query: str, candidate_ids: List[str], limit: int
    ) -> List[Dict[str, Any]]:
        # [ìˆ˜ì •] ì„¸ì…˜ ê´€ë¦¬ ë¡œì§ ì¶”ê°€
        session = self.session if self.session else AsyncSessionLocal()
        should_close = self.session is None
        
        try:
            embedding_model = get_embedding_model()
            if not embedding_model or not candidate_ids:
                return []
            
            query_embedding = embedding_model.encode(query, convert_to_numpy=True).tolist()
            embedding_str = "[" + ",".join(map(str, query_embedding)) + "]"
            sql_query = text(f"""
                SELECT 
                    panel_id,
                    1 - (embedding <=> CAST(:embedding_str AS vector)) as similarity
                FROM panel_summary_segments
                WHERE embedding IS NOT NULL
                  AND panel_id = ANY(:candidate_ids)
                ORDER BY embedding <=> CAST(:embedding_str AS vector)
                LIMIT :limit_val
            """)
            result = await session.execute(sql_query, {
                "embedding_str": embedding_str,
                "candidate_ids": candidate_ids,
                "limit_val": limit * 5
            })
            rows = result.fetchall()
            best_by_panel: Dict[str, float] = {}
            for panel_id, similarity in rows:
                if panel_id:
                    panel_id_str = str(panel_id)
                    similarity_float = float(similarity) if similarity else 0.0
                    if panel_id_str not in best_by_panel or similarity_float > best_by_panel[panel_id_str]:
                        best_by_panel[panel_id_str] = similarity_float
            
            sorted_items = sorted(best_by_panel.items(), key=lambda x: x[1], reverse=True)[:limit]
            return [
                {"panel_id": pid, "score": score, "source": "vector_filtered"}
                for pid, score in sorted_items
            ]
        except Exception as e:
            print(f"  âŒ í•„í„°ë§ëœ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
        finally:
            # [ì¤‘ìš”] ì„¸ì…˜ ë‹«ê¸°
            if should_close:
                await session.close()
