"""
ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ìœ¼ë¡œ summary_text ì—…ë°ì´íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ì— ë‹µë³€ë§Œ ì €ì¥ëœ summary_textë¥¼ "ì§ˆë¬¸ ë‹µë³€" í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
    python backend/scripts/migrate_qa_format.py --batch-size 1000
"""

import argparse
import asyncio
import json
import sys
import time
from pathlib import Path
from typing import Any, Dict, Optional

from dotenv import load_dotenv
from sqlalchemy import text

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = str(Path(__file__).resolve().parents[2])
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from backend.repositories.database import AsyncSessionLocal

load_dotenv(Path(PROJECT_ROOT) / ".env")


# í•„ë“œëª… â†’ í•œêµ­ì–´ ë§¤í•‘ (column_metadataì— ì—†ëŠ” í•„ë“œìš©)
FIELD_NAME_KO_MAP = {
    "fitness_management_method": "ìš´ë™ ê´€ë¦¬ ë°©ë²•",
    "chatbot_experience": "ì±—ë´‡ ì‚¬ìš© ê²½í—˜",
    "chatbot_main_purpose": "ì±—ë´‡ ì£¼ìš” ì‚¬ìš© ëª©ì ",
    "main_chatbot_used": "ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡",
    "preferred_chatbot": "ì„ í˜¸í•˜ëŠ” ì±—ë´‡",
    "ai_usage_field": "AI ì‚¬ìš© ë¶„ì•¼",
    "main_apps_used": "ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì•±",
    "ott_service_count": "ì´ìš©í•˜ëŠ” OTT ì„œë¹„ìŠ¤ ê°œìˆ˜",
    "skincare_spending_monthly": "ì›” ìŠ¤í‚¨ì¼€ì–´ ì§€ì¶œ",
    "skincare_considerations": "ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ì„ íƒ ì‹œ ê³ ë ¤ì‚¬í•­",
    "skin_satisfaction": "í”¼ë¶€ ë§Œì¡±ë„",
    "most_effective_diet_experience": "ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ ë‹¤ì´ì–´íŠ¸ ê²½í—˜",
    "most_saved_photos_topic": "ê°€ì¥ ë§ì´ ì €ì¥í•˜ëŠ” ì‚¬ì§„ ì£¼ì œ",
    "preferred_spending_category": "ì„ í˜¸í•˜ëŠ” ì†Œë¹„ ì¹´í…Œê³ ë¦¬",
    "high_spending_category": "ë†’ì€ ì§€ì¶œ ì¹´í…Œê³ ë¦¬",
    "preferred_new_year_gift": "ì„ í˜¸í•˜ëŠ” ì„¤ ì„ ë¬¼",
    "preferred_water_play_area": "ì„ í˜¸í•˜ëŠ” ë¬¼ë†€ì´ ì¥ì†Œ",
    "preferred_overseas_destination": "ì„ í˜¸í•˜ëŠ” í•´ì™¸ ì—¬í–‰ì§€",
    "preferred_summer_snack": "ì„ í˜¸í•˜ëŠ” ì—¬ë¦„ ê°„ì‹",
    "memorable_childhood_winter_activity": "ê¸°ì–µì— ë‚¨ëŠ” ì–´ë¦° ì‹œì ˆ ê²¨ìš¸ í™œë™",
    "travel_style": "ì—¬í–‰ ìŠ¤íƒ€ì¼",
    "traditional_market_visit_frequency": "ì „í†µì‹œì¥ ë°©ë¬¸ ë¹ˆë„",
    "main_quick_delivery_products": "ì£¼ë¡œ ì£¼ë¬¸í•˜ëŠ” í€µë°°ì†¡ ìƒí’ˆ",
    "reward_points_interest": "ë¦¬ì›Œë“œ í¬ì¸íŠ¸ ê´€ì‹¬ë„",
    "lifestyle_values": "ë¼ì´í”„ìŠ¤íƒ€ì¼ ê°€ì¹˜ê´€",
    "privacy_habits": "ê°œì¸ì •ë³´ ë³´í˜¸ ìŠµê´€",
    "reducing_plastic_bags": "ë¹„ë‹ë´‰ì§€ ì‚¬ìš© ì¤„ì´ê¸° ë°©ë²•",
    "rainy_day_coping_method": "ë¹„ ì˜¤ëŠ” ë‚  ëŒ€ì²˜ ë°©ë²•",
    "late_night_snack_method": "ì•¼ì‹ ì„­ì·¨ ë°©ë²•",
    "morning_wakeup_method": "ì•„ì¹¨ ê¸°ìƒ ë°©ë²•",
    "solo_dining_frequency": "í˜¼ë°¥ ë¹ˆë„",
    "preferred_chocolate_situation": "ì´ˆì½œë¦¿ì„ ì„ í˜¸í•˜ëŠ” ìƒí™©",
    "moving_stress_factors": "ì´ì‚¬ ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸",
    "conditions_for_happy_old_age": "í–‰ë³µí•œ ë…¸í›„ë¥¼ ìœ„í•œ ì¡°ê±´",
    "pets": "ë°˜ë ¤ë™ë¬¼ ê²½í—˜",
    "stress_factors": "ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸",
    "stress_relief_method": "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ë°©ë²•",
    "summer_fashion_essential": "ì—¬ë¦„ íŒ¨ì…˜ í•„ìˆ˜í’ˆ",
    "summer_sweat_discomfort": "ì—¬ë¦„ ë•€ ë¶ˆí¸í•¨",
    "summer_worries": "ì—¬ë¦„ ê±±ì •",
    "waste_disposal_method": "ì“°ë ˆê¸° ì²˜ë¦¬ ë°©ë²•",
}


def load_column_metadata() -> Dict[str, Dict[str, Any]]:
    """column_metadata.jsonì„ ë¡œë“œí•˜ì—¬ í•„ë“œëª… â†’ ë©”íƒ€ë°ì´í„° ë§¤í•‘ ë°˜í™˜"""
    metadata_path = Path(PROJECT_ROOT) / "backend" / "data" / "column_metadata.json"
    try:
        with open(metadata_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ column_metadata.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def field_name_to_korean(field_name: str) -> str:
    """í•„ë“œëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
    # ë§¤í•‘ í…Œì´ë¸” í™•ì¸
    if field_name.lower() in FIELD_NAME_KO_MAP:
        return FIELD_NAME_KO_MAP[field_name.lower()]
    
    # snake_caseë¥¼ í•œê¸€ë¡œ ë³€í™˜ ì‹œë„
    words = field_name.lower().split("_")
    # ê°„ë‹¨í•œ ì˜ì–´ ë‹¨ì–´ â†’ í•œê¸€ ë³€í™˜
    word_map = {
        "fitness": "ìš´ë™", "management": "ê´€ë¦¬", "method": "ë°©ë²•",
        "chatbot": "ì±—ë´‡", "experience": "ê²½í—˜", "main": "ì£¼ìš”", "purpose": "ëª©ì ",
        "used": "ì‚¬ìš©", "preferred": "ì„ í˜¸", "ai": "AI", "usage": "ì‚¬ìš©", "field": "ë¶„ì•¼",
        "apps": "ì•±", "ott": "OTT", "service": "ì„œë¹„ìŠ¤", "count": "ê°œìˆ˜",
        "skincare": "ìŠ¤í‚¨ì¼€ì–´", "spending": "ì§€ì¶œ", "monthly": "ì›”",
        "considerations": "ê³ ë ¤ì‚¬í•­", "skin": "í”¼ë¶€", "satisfaction": "ë§Œì¡±ë„",
        "most": "ê°€ì¥", "effective": "íš¨ê³¼ì ì¸", "diet": "ë‹¤ì´ì–´íŠ¸",
        "saved": "ì €ì¥í•œ", "photos": "ì‚¬ì§„", "topic": "ì£¼ì œ",
        "spending": "ì§€ì¶œ", "category": "ì¹´í…Œê³ ë¦¬", "high": "ë†’ì€",
        "new": "ìƒˆí•´", "year": "ë…„", "gift": "ì„ ë¬¼",
        "water": "ë¬¼", "play": "ë†€ì´", "area": "ì¥ì†Œ",
        "overseas": "í•´ì™¸", "destination": "ì—¬í–‰ì§€",
        "summer": "ì—¬ë¦„", "snack": "ê°„ì‹",
        "memorable": "ê¸°ì–µì— ë‚¨ëŠ”", "childhood": "ì–´ë¦° ì‹œì ˆ", "winter": "ê²¨ìš¸", "activity": "í™œë™",
        "travel": "ì—¬í–‰", "style": "ìŠ¤íƒ€ì¼",
        "traditional": "ì „í†µ", "market": "ì‹œì¥", "visit": "ë°©ë¬¸", "frequency": "ë¹ˆë„",
        "quick": "í€µ", "delivery": "ë°°ì†¡", "products": "ìƒí’ˆ",
        "reward": "ë¦¬ì›Œë“œ", "points": "í¬ì¸íŠ¸", "interest": "ê´€ì‹¬ë„",
        "lifestyle": "ë¼ì´í”„ìŠ¤íƒ€ì¼", "values": "ê°€ì¹˜ê´€",
        "privacy": "ê°œì¸ì •ë³´", "habits": "ìŠµê´€",
        "reducing": "ì¤„ì´ê¸°", "plastic": "ë¹„ë‹", "bags": "ë´‰ì§€",
        "rainy": "ë¹„ ì˜¤ëŠ”", "day": "ë‚ ", "coping": "ëŒ€ì²˜",
        "late": "ëŠ¦ì€", "night": "ë°¤",
        "morning": "ì•„ì¹¨", "wakeup": "ê¸°ìƒ",
        "solo": "í˜¼ì", "dining": "ì‹ì‚¬",
        "chocolate": "ì´ˆì½œë¦¿", "situation": "ìƒí™©",
        "moving": "ì´ì‚¬", "stress": "ìŠ¤íŠ¸ë ˆìŠ¤", "factors": "ìš”ì¸",
        "conditions": "ì¡°ê±´", "for": "ì„ ìœ„í•œ", "happy": "í–‰ë³µí•œ", "old": "ë…¸í›„", "age": "ë‚˜ì´",
        "pets": "ë°˜ë ¤ë™ë¬¼",
    }
    
    translated = []
    for word in words:
        if word in word_map:
            translated.append(word_map[word])
        else:
            translated.append(word)
    
    return " ".join(translated)


def generate_question(field_name: str, metadata: Optional[Dict[str, Any]] = None) -> str:
    """í•„ë“œëª…ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±"""
    if metadata and "name_ko" in metadata:
        field_name_ko = metadata["name_ko"]
    else:
        field_name_ko = field_name_to_korean(field_name)
    
    # ì¡°ì‚¬ ì²˜ë¦¬
    last_char = field_name_ko[-1]
    if ord(last_char) >= 0xAC00 and ord(last_char) <= 0xD7A3:
        if (ord(last_char) - 0xAC00) % 28 == 0:
            return f"{field_name_ko}ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        else:
            return f"{field_name_ko}ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    else:
        return f"{field_name_ko}ì€ ë¬´ì—‡ì¸ê°€ìš”?"


async def migrate_qa_format(
    batch_size: int = 5000,  # 1000 â†’ 5000 (5ë°° ì¦ê°€)
    start_from: int = 0,
    dry_run: bool = False
):
    """ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ìœ¼ë¡œ summary_text ì—…ë°ì´íŠ¸
    
    Args:
        batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë ˆì½”ë“œ ìˆ˜
        start_from: ì‹œì‘ ì˜¤í”„ì…‹ (ì¬ì‹œì‘ìš©)
        dry_run: ì‹¤ì œ ì—…ë°ì´íŠ¸ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ
    """
    print("="*80)
    print("ğŸ” ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    print("="*80)
    print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    print(f"ì‹œì‘ ì˜¤í”„ì…‹: {start_from}")
    print(f"ë“œë¼ì´ëŸ° ëª¨ë“œ: {dry_run}")
    print()
    
    # column_metadata ë¡œë“œ
    print("ğŸ“š ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘...")
    column_metadata = load_column_metadata()
    print(f"âœ… {len(column_metadata)}ê°œ í•„ë“œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n")
    
    async with AsyncSessionLocal() as session:
        # ì „ì²´ ê°œìˆ˜ í™•ì¸
        count_query = text("""
            SELECT COUNT(*) 
            FROM panel_summary_segments 
            WHERE summary_text IS NOT NULL
        """)
        result = await session.execute(count_query)
        total_count = result.scalar()
        print(f"ğŸ“Š ì´ ì²˜ë¦¬ ëŒ€ìƒ: {total_count:,}ê°œ\n")
        
        start_time = time.time()
        processed = 0
        updated = 0
        errors = 0
        offset = start_from
        
        while offset < total_count:
            batch_start_time = time.time()
            
            # ë°°ì¹˜ ì¡°íšŒ
            query = text("""
                SELECT panel_id, segment_name, summary_text
                FROM panel_summary_segments
                WHERE summary_text IS NOT NULL
                ORDER BY panel_id, segment_name
                LIMIT :limit_val OFFSET :offset_val
            """)
            result = await session.execute(query, {
                "limit_val": batch_size,
                "offset_val": offset
            })
            rows = result.fetchall()
            
            if not rows:
                break
            
            batch_updates = []
            update_params = []
            
            # ëª¨ë“  ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„
            for panel_id, segment_name, current_text in rows:
                try:
                    # segment_nameì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ í•„ë“œëª…ìœ¼ë¡œ ì‚¬ìš©
                    field_name = segment_name.lower()
                    
                    # ì´ë¯¸ ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                    if "ì€ ë¬´ì—‡ì¸ê°€ìš”?" in current_text or "ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" in current_text or "ë¬´ì—‡ì¸ê°€ìš”?" in current_text:
                        # ì´ë¯¸ ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                        continue
                    
                    # ì§ˆë¬¸ ìƒì„±
                    metadata = column_metadata.get(field_name)
                    question = generate_question(field_name, metadata)
                    
                    # ì§ˆë¬¸ + ë‹µë³€ ê²°í•©
                    new_text = f"{question} {current_text}"
                    
                    # bulk updateë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
                    update_params.append({
                        "new_text": new_text,
                        "panel_id": panel_id,
                        "segment_name": segment_name
                    })
                    
                    batch_updates.append({
                        "panel_id": panel_id,
                        "segment_name": segment_name,
                        "old": current_text[:50],
                        "new": new_text[:80]
                    })
                    updated += 1
                    
                except Exception as e:
                    errors += 1
                    print(f"  âŒ ì˜¤ë¥˜ (Panel {panel_id}, Segment {segment_name}): {e}", flush=True)
            
            # Bulk update ì‹¤í–‰ (executemany ì‚¬ìš©)
            if not dry_run and update_params:
                try:
                    update_query = text("""
                        UPDATE panel_summary_segments
                        SET summary_text = :new_text,
                            ts_vector_korean = to_tsvector('korean', :new_text),
                            updated_at = NOW()
                        WHERE panel_id = :panel_id 
                          AND segment_name = :segment_name
                    """)
                    # executemanyë¡œ í•œ ë²ˆì— ì‹¤í–‰
                    await session.execute(update_query, update_params)
                    await session.commit()
                except Exception as e:
                    print(f"  âŒ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", flush=True)
                    await session.rollback()
                    errors += len(update_params)
            
            processed += len(rows)
            batch_time = time.time() - batch_start_time
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            progress = (processed / total_count) * 100
            elapsed = time.time() - start_time
            avg_time_per_record = elapsed / processed if processed > 0 else 0
            remaining = (total_count - processed) * avg_time_per_record
            
            print(f"--- ë°°ì¹˜ {offset // batch_size + 1} (ì˜¤í”„ì…‹: {offset:,} ~ {offset + len(rows):,}) ---", flush=True)
            print(f"  âœ… ì²˜ë¦¬: {len(rows)}ê°œ (ì—…ë°ì´íŠ¸: {len(batch_updates)}ê°œ, ì˜¤ë¥˜: {errors}ê°œ)", flush=True)
            print(f"  â±ï¸ ë°°ì¹˜ ì‹œê°„: {batch_time:.2f}ì´ˆ", flush=True)
            print(f"  ğŸ“ˆ ì „ì²´ ì§„í–‰: {processed:,}/{total_count:,} ({progress:.1f}%)", flush=True)
            print(f"  â³ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„", flush=True)
            
            # ìƒ˜í”Œ ì¶œë ¥ (ì²« ë°°ì¹˜ë§Œ)
            if offset == start_from and batch_updates:
                print(f"\n  ğŸ“ ìƒ˜í”Œ ë³€í™˜:")
                for sample in batch_updates[:3]:
                    print(f"    {sample['segment_name']}:")
                    print(f"      ì´ì „: {sample['old']}...")
                    print(f"      ì´í›„: {sample['new']}...")
                print()
            
            offset += batch_size
            
            # ë°°ì¹˜ ê°„ ì§§ì€ ëŒ€ê¸° (DB ë¶€í•˜ ë°©ì§€)
            if not dry_run:
                await asyncio.sleep(0.1)
        
        # ìµœì¢… í†µê³„
        total_time = time.time() - start_time
        print("\n" + "="*80)
        print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print("="*80)
        print(f"ì´ ì²˜ë¦¬: {processed:,}ê°œ")
        print(f"ì—…ë°ì´íŠ¸: {updated:,}ê°œ")
        print(f"ì˜¤ë¥˜: {errors}ê°œ")
        print(f"ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
        print(f"í‰ê·  ì²˜ë¦¬ ì†ë„: {processed/total_time:.1f}ê°œ/ì´ˆ")
        
        if dry_run:
            print("\nâš ï¸ ë“œë¼ì´ëŸ° ëª¨ë“œì˜€ìŠµë‹ˆë‹¤. ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ ë§ˆì´ê·¸ë ˆì´ì…˜")
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1000,
        help="í•œ ë²ˆì— ì²˜ë¦¬í•  ë ˆì½”ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 1000)"
    )
    parser.add_argument(
        "--start-from",
        type=int,
        default=0,
        help="ì‹œì‘ ì˜¤í”„ì…‹ (ì¬ì‹œì‘ìš©, ê¸°ë³¸ê°’: 0)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ ì—…ë°ì´íŠ¸ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰"
    )
    
    args = parser.parse_args()
    
    try:
        await migrate_qa_format(
            batch_size=args.batch_size,
            start_from=args.start_from,
            dry_run=args.dry_run
        )
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ë‹¤ìŒ ì‹¤í–‰ ì‹œ --start-from {args.start_from} ì˜µì…˜ìœ¼ë¡œ ì¬ì‹œì‘í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

